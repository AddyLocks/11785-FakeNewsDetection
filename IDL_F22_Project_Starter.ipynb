{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4qfYrVoO4v"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd5aNaLVoR_g"
      },
      "source": [
        "## wandb\n",
        "\n",
        "You will need to fetch your api key from wandb.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA9qZoIDcx-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b75ade-e304-4055-b526-97126cc478da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 40.2 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 48.9 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 54.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 51 kB 40.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 43.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71 kB 41.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81 kB 42.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92 kB 42.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 122 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 143 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 163 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 174 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 184 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 215 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 235 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 256 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 276 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 286 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 296 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 307 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 327 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 348 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 358 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 368 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 378 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 399 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 409 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 419 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 430 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 440 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 450 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 460 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 471 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 491 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 501 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 512 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 522 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 542 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 552 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 563 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 573 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 583 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 593 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 604 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 614 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 624 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 634 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 645 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 655 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 665 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 675 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 686 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 696 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 716 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 727 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 737 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 747 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 757 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 768 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 778 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 788 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 798 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 808 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 819 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 829 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 839 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 849 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 860 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 870 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 880 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 890 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 901 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 911 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 921 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 931 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 942 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 952 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 962 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 972 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 983 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 993 kB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.0 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.0 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.0 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.0 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.2 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.6 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.7 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.8 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.9 MB 44.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9 MB 44.3 MB/s \n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONgAWhqdoYy-"
      },
      "source": [
        "## Misc\n",
        "\n",
        "This may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS7a7xeEoaV9"
      },
      "outputs": [],
      "source": [
        "!pip install torchsummaryX\n",
        "!pip install slugify\n",
        "!pip install pytorch_pretrained_bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVONJxCobPc"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78ZTCIXoof2f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time as Time\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "from pytorch_pretrained_bert import BertConfig\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "import wandb\n",
        "import copy\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9v5ewZDMpYA"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cp-716IMZRd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiS6pZ3Vveb0"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/glove'\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -qo 'glove.6B.zip' -d '/content/glove'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnIMttYa5EGc"
      },
      "source": [
        "# Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeEA5A_y5HCw"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"num_labels\" : 2, # True or False Classification\n",
        "    \"lr\" : 2e-3,\n",
        "    \"epochs\" : 50,\n",
        "    'batch_size' : 8,\n",
        "    #'LR scheduler': 'CosineAnnealingLR',\n",
        "    'LR scheduler': 'ReduceLROnPlateau',\n",
        "                'scheduler factor': 0.5,\n",
        "    'scheduler threshold': 0.01,\n",
        "            'scheduler patience': 5,\n",
        "   #'scheduler Tmax': 0,\n",
        "    } # Feel free to add more items here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n37yR-fl5Yxg"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCf4pk9y5bH3"
      },
      "outputs": [],
      "source": [
        "# remeber to change the path if you are not on google colab and directly uploading\n",
        "train_path = '/content/train2.tsv'\n",
        "test_path = '/content/test2.tsv'\n",
        "val_path = '/content/val2.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9zWt35f5pDj"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_path, sep=\"\\t\", header=None)\n",
        "test_df = pd.read_csv(test_path, sep=\"\\t\", header=None)\n",
        "val_df = pd.read_csv(val_path, sep=\"\\t\", header=None)\n",
        "\n",
        "# Fill nan (empty boxes) with 0\n",
        "train_df = train_df.fillna(0)\n",
        "test_df = test_df.fillna(0)\n",
        "val_df = val_df.fillna(0)\n",
        "\n",
        "train = train_df.values\n",
        "test = test_df.values\n",
        "val = val_df.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3TkMhc78nKV"
      },
      "outputs": [],
      "source": [
        "# label: ground truth results from politifacts\n",
        "labels = {'train':[train[i][2] for i in range(len(train))], 'test':[test[i][2] for i in range(len(test))], 'val':[val[i][2] for i in range(len(val))]}\n",
        "# Short Statement\n",
        "statements = {'train':[train[i][3] for i in range(len(train))], 'test':[test[i][3] for i in range(len(test))], 'val':[val[i][3] for i in range(len(val))]}\n",
        "# Topic of Statement\n",
        "subjects = {'train':[train[i][4] for i in range(len(train))], 'test':[test[i][4] for i in range(len(test))], 'val':[val[i][4] for i in range(len(val))]}\n",
        "# Speaker\n",
        "speakers = {'train':[train[i][5] for i in range(len(train))], 'test':[test[i][5] for i in range(len(test))], 'val':[val[i][5] for i in range(len(val))]}\n",
        "# Speaker job or title\n",
        "jobs = {'train':[train[i][6] for i in range(len(train))], 'test':[test[i][6] for i in range(len(test))], 'val':[val[i][6] for i in range(len(val))]}\n",
        "# State of Relevance\n",
        "states = {'train':[train[i][7] for i in range(len(train))], 'test':[test[i][7] for i in range(len(test))], 'val':[val[i][7] for i in range(len(val))]}\n",
        "# party affiliation\n",
        "affiliations = {'train':[train[i][8] for i in range(len(train))], 'test':[test[i][8] for i in range(len(test))], 'val':[val[i][8] for i in range(len(val))]}\n",
        "# total history of speaker(count of barely true, false, half true, mostly true, pants on fire respectively)\n",
        "credits = {'train':[train[i][9:14] for i in range(len(train))], 'test':[test[i][9:14] for i in range(len(test))], 'val':[val[i][9:14] for i in range(len(val))]}\n",
        "# venue of statement\n",
        "contexts = {'train':[train[i][14] for i in range(len(train))], 'test':[test[i][14] for i in range(len(test))], 'val':[val[i][14] for i in range(len(val))]}\n",
        "# verdict justification from politifacts\n",
        "justification = {'train':[train[i][15] for i in range(len(train))], 'test':[test[i][15] for i in range(len(test))], 'val':[val[i][15] for i in range(len(val))]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yBDQOrR93wo"
      },
      "outputs": [],
      "source": [
        "# currently only do 2 way classfication & simplify 6 way label into true and false\n",
        "# convert label to 2 hot based on verdict label\n",
        "if config[\"num_labels\"] ==2:\n",
        "  def onehot(label):\n",
        "    label_onehot = [0]*len(label)\n",
        "    for i in range(len(label)):\n",
        "      if label[i] =='true' or label[i] =='mostly-true' or label[i] =='half-true':\n",
        "        label_onehot[i] = [1,0]\n",
        "      elif label[i] =='barely-true' or label[i] =='false' or label[i] =='pants-fire':\n",
        "        label_onehot[i] = [0,1]\n",
        "      else:\n",
        "        print('Unexpected Label. Set vector to [0]')\n",
        "    return label_onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9Qc774Z_lVc"
      },
      "outputs": [],
      "source": [
        "# Convert to one hot\n",
        "label_onehot = {'train':onehot(labels['train']), 'test':onehot(labels['test']), 'val':onehot(labels['val'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWIGKC5TBWjz"
      },
      "outputs": [],
      "source": [
        "# Meta data\n",
        "metadata = {'train':[0]*len(train), 'val':[0]*len(val), 'test':[0]*len(test)}\n",
        "\n",
        "for i in range(len(train)):\n",
        "    subject = subjects['train'][i]\n",
        "    if subject == 0:\n",
        "        subject = 'None'\n",
        "\n",
        "    speaker = speakers['train'][i]\n",
        "    if speaker == 0:\n",
        "        speaker = 'None'\n",
        "\n",
        "    job = jobs['train'][i]\n",
        "    if job == 0:\n",
        "        job = 'None'\n",
        "\n",
        "    state = states['train'][i]\n",
        "    if state == 0:\n",
        "        state = 'None'\n",
        "\n",
        "    affiliation = affiliations['train'][i]\n",
        "    if affiliation == 0:\n",
        "        affiliation = 'None'\n",
        "\n",
        "    context = contexts['train'][i]\n",
        "    if context == 0 :\n",
        "        context = 'None'\n",
        "    if i == 0:\n",
        "      print(subject)\n",
        "    meta = subject + ' ' + speaker + ' ' + job + ' ' + state + ' ' + affiliation + ' ' + context\n",
        "    if i == 0:\n",
        "      print(meta)\n",
        "    metadata['train'][i] = meta\n",
        "\n",
        "for i in range(len(val)):\n",
        "    subject = subjects['val'][i]\n",
        "    if subject == 0:\n",
        "        subject = 'None'\n",
        "\n",
        "    speaker = speakers['val'][i]\n",
        "    if speaker == 0:\n",
        "        speaker = 'None'\n",
        "\n",
        "    job = jobs['val'][i]\n",
        "    if job == 0:\n",
        "        job = 'None'\n",
        "\n",
        "    state = states['val'][i]\n",
        "    if state == 0:\n",
        "        state = 'None'\n",
        "\n",
        "    affiliation = affiliations['val'][i]\n",
        "    if affiliation == 0:\n",
        "        affiliation = 'None'\n",
        "\n",
        "    context = contexts['val'][i]\n",
        "    if context == 0 :\n",
        "        context = 'None'\n",
        "\n",
        "    meta = subject + ' ' + speaker + ' ' + job + ' ' + state + ' ' + affiliation + ' ' + context\n",
        "\n",
        "    metadata['val'][i] = meta\n",
        "\n",
        "for i in range(len(test)):\n",
        "    subject = subjects['test'][i]\n",
        "    if subject == 0:\n",
        "        subject = 'None'\n",
        "\n",
        "    speaker = speakers['test'][i]\n",
        "    if speaker == 0:\n",
        "        speaker = 'None'\n",
        "\n",
        "    job = jobs['test'][i]\n",
        "    if job == 0:\n",
        "        job = 'None'\n",
        "\n",
        "    state = states['test'][i]\n",
        "    if state == 0:\n",
        "        state = 'None'\n",
        "\n",
        "    affiliation = affiliations['test'][i]\n",
        "    if affiliation == 0:\n",
        "        affiliation = 'None'\n",
        "\n",
        "    context = contexts['test'][i]\n",
        "    if context == 0 :\n",
        "        context = 'None'\n",
        "\n",
        "    meta = subject + ' ' + speaker + ' ' + job + ' ' + state + ' ' + affiliation + ' ' + context\n",
        "\n",
        "    metadata['test'][i] = meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF4_ku_TDV_G"
      },
      "outputs": [],
      "source": [
        "# Credit score calculation\n",
        "# barely true weighs 0.75, false weighs 0.9, half true weigh 0.5, mostly true weigh 0.2, pants on fire weigh 1\n",
        "credit_score = {'train':[0]*len(train), 'val':[0]*len(val), 'test':[0]*len(test)}\n",
        "for i in range(len(train)):\n",
        "    credit = credits['train'][i]\n",
        "    if sum(credit) == 0:\n",
        "        score = 0.5\n",
        "    else:\n",
        "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
        "    credit_score['train'][i] = [score for i in range(2304)]\n",
        "\n",
        "for i in range(len(val)):\n",
        "    credit = credits['val'][i]\n",
        "    if sum(credit) == 0:\n",
        "        score = 0.5\n",
        "    else:\n",
        "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
        "    credit_score['val'][i] = [score for i in range(2304)]\n",
        "\n",
        "for i in range(len(test)):\n",
        "    credit = credits['test'][i]\n",
        "    if sum(credit) == 0:\n",
        "        score = 0.5\n",
        "    else:\n",
        "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
        "    credit_score['test'][i] = [score for i in range(2304)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ORNHnSFroP0"
      },
      "source": [
        "# Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRVPUbWMFzBk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Loading the statements\n",
        "X_train = statements['train']\n",
        "y_train = label_onehot['train']\n",
        "\n",
        "X_val = statements['val']\n",
        "y_val = label_onehot['val']\n",
        "\n",
        "\n",
        "X_test = statements['test']\n",
        "y_test = label_onehot['test']\n",
        "\n",
        "# Loading the justification\n",
        "X_train_just = justification['train']\n",
        "\n",
        "X_val_just = justification['val']\n",
        "\n",
        "\n",
        "X_test_just = justification['test']\n",
        "\n",
        "\n",
        "# Loading the meta data\n",
        "X_train_meta = metadata['train']\n",
        "X_val_meta = metadata['val']\n",
        "X_test_meta = metadata['test']\n",
        "\n",
        "# Loading Credit scores\n",
        "\n",
        "X_train_credit = credit_score['train']\n",
        "X_val_credit = credit_score['val']\n",
        "X_test_credit = credit_score['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrLbmyvZGTAJ"
      },
      "outputs": [],
      "source": [
        "max_seq_length_stat = 64\n",
        "max_seq_length_just = 256\n",
        "max_seq_length_meta = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmNBKf4JrLV"
      },
      "source": [
        "### Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afd0_vlbJmr_"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, xy_list ,transform=None): \n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        '''\n",
        "\n",
        "        # Load the xy list\n",
        "\n",
        "        self.x_y_list = xy_list\n",
        "        self.length = len(xy_list[0])\n",
        "        for i in range(self.length):\n",
        "        #   Load in each statement and tokenize\n",
        "            #print(self.x_y_list[0][i])\n",
        "            tokenized_stat = tokenizer.tokenize(self.x_y_list[0][i])\n",
        "            if len(tokenized_stat) > max_seq_length_stat:\n",
        "              # clip if the statement is too long\n",
        "                tokenized_stat = tokenized_stat[:max_seq_length_stat]\n",
        "\n",
        "            # convert statement to ids\n",
        "            ids_stat  = tokenizer.convert_tokens_to_ids(tokenized_stat)\n",
        "            # pad the statement to given length\n",
        "            padding = [0] * (max_seq_length_stat - len(ids_stat))\n",
        "\n",
        "            ids_stat += padding\n",
        "            # sanity check\n",
        "            assert len(ids_stat) == max_seq_length_stat\n",
        "            \n",
        "            #if i == 1:\n",
        "            #  print(ids_stat)\n",
        "            ids_stat = torch.tensor(ids_stat)\n",
        "            \n",
        "            if self.x_y_list[1][i] == 0:\n",
        "                self.x_y_list[1][i] = 'No justification'\n",
        "\n",
        "            #print(self.x_y_list[1][i])\n",
        "            tokenized_just = tokenizer.tokenize(self.x_y_list[1][i])\n",
        "            if len(tokenized_just) > max_seq_length_just:\n",
        "              # clip if the statement is too long\n",
        "                tokenized_just = tokenized_just[:max_seq_length_just]\n",
        "\n",
        "            # convert statement to ids\n",
        "            ids_just  = tokenizer.convert_tokens_to_ids(tokenized_just)\n",
        "            # pad the statement to given length\n",
        "            padding = [0] * (max_seq_length_just - len(ids_just))\n",
        "\n",
        "            ids_just += padding\n",
        "            # sanity check\n",
        "            assert len(ids_just) == max_seq_length_just\n",
        "\n",
        "            #if i == 1:\n",
        "            #  print(ids_just)\n",
        "            ids_just = torch.tensor(ids_just)\n",
        "\n",
        "            #print(self.x_y_list[2][i])\n",
        "            tokenized_meta = tokenizer.tokenize(self.x_y_list[2][i])\n",
        "            if len(tokenized_meta) > max_seq_length_meta:\n",
        "              # clip if the statement is too long\n",
        "                tokenized_meta = tokenized_meta[:max_seq_length_meta]\n",
        "\n",
        "            # convert statement to ids\n",
        "            ids_meta  = tokenizer.convert_tokens_to_ids(tokenized_meta)\n",
        "            # pad the statement to given length\n",
        "            padding = [0] * (max_seq_length_meta - len(ids_meta))\n",
        "\n",
        "            ids_meta += padding\n",
        "            # sanity check\n",
        "            assert len(ids_meta) == max_seq_length_meta\n",
        "\n",
        "            ids_meta = torch.tensor(ids_meta)\n",
        "            \n",
        "            credit_scr = torch.tensor(self.x_y_list[3][i]) # Credit score\n",
        "\n",
        "            #if i == 1:\n",
        "            #  print(credit_scr)\n",
        "\n",
        "            label = torch.from_numpy(np.array(self.x_y_list[4][i]))\n",
        "\n",
        "            #if i == 1:\n",
        "            #  print(label)\n",
        "\n",
        "            self.x_y_list[0][i] = ids_stat\n",
        "            self.x_y_list[1][i] = ids_just\n",
        "            self.x_y_list[2][i] = ids_meta\n",
        "            self.x_y_list[3][i] = credit_scr\n",
        "            self.x_y_list[4][i] = label\n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        '''\n",
        "        TODO: What do we return here?\n",
        "        '''\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "        \n",
        "        ids_stat = self.x_y_list[0][ind] \n",
        "        ids_just = self.x_y_list[1][ind]\n",
        "        ids_meta = self.x_y_list[2][ind] \n",
        "        credit_scr = self.x_y_list[3][ind] \n",
        "        label = self.x_y_list[4][ind]\n",
        "\n",
        "        return ids_stat, ids_just, ids_meta, credit_scr, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt-veYcdL6Fe"
      },
      "source": [
        "### Data - Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4icymeX1ImUN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = config['batch_size'] # Increase if your device can handle it\n",
        "\n",
        "transforms = [] # set of tranformations\n",
        "# You may pass this as a parameter to the dataset class above\n",
        "# This will help modularize your implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmuPk9J6L8dz"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_kG0gU2x4hH"
      },
      "outputs": [],
      "source": [
        "# get me RAMMM!!!! \n",
        "import gc \n",
        "gc.collect()\n",
        "X_train_meta[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mzoYfTKu14s"
      },
      "outputs": [],
      "source": [
        "# Create objects for the dataset class\n",
        "#train_data = TextDataset([X_train[:100], X_train_just[:100], X_train_meta[:100], X_train_credit[:100], y_train[:100]])\n",
        "train_data = TextDataset([X_train, X_train_just, X_train_meta, X_train_credit, y_train])\n",
        "val_data = TextDataset([X_val, X_val_just, X_val_meta, X_val_credit, y_val]) \n",
        "test_data = TextDataset([X_test, X_test_just, X_test_meta, X_test_credit, y_test]) \n",
        "\n",
        "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, num_workers= 4,\n",
        "                                           batch_size=BATCH_SIZE, pin_memory= True,\n",
        "                                           shuffle= True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, num_workers= 2,\n",
        "                                           batch_size=BATCH_SIZE, pin_memory= True,\n",
        "                                           shuffle= True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, num_workers= 2,\n",
        "                                           batch_size=BATCH_SIZE, pin_memory= True,\n",
        "                                           shuffle= True)\n",
        "\n",
        "print(\"Batch size: \", BATCH_SIZE)\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXMtwyviKaxK"
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "for data in train_loader:\n",
        "    x, y, z, m, n = data\n",
        "    print(x.shape, y.shape, z.shape)\n",
        "    x, y, z, m, n = x.to(device), y.to(device), z.to(device), m.to(device), n.to(device) \n",
        "    break "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly4mjUUUuJhy"
      },
      "source": [
        "# Model Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLad4pChcuvX"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "config_bert = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)"
      ],
      "metadata": {
        "id": "cmocsazoDQF_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "        def __init__(self, hidden_size, eps=1e-12):\n",
        "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "            \"\"\"\n",
        "            super(BertLayerNorm, self).__init__()\n",
        "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "            self.variance_epsilon = eps\n",
        "\n",
        "        def forward(self, x):\n",
        "            u = x.mean(-1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "            return self.weight * x + self.bias"
      ],
      "metadata": {
        "id": "CukOseHrDQF_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQhvHr71GJfq"
      },
      "outputs": [],
      "source": [
        "class BertForSequenceClassification(nn.Module):\n",
        "    def __init__(self, num_labels=2): # Change number of labels here.\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(config_bert.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config_bert.hidden_size*3, num_labels)\n",
        "        #self.fc1 = nn.Linear(config_bert.hidden_size*2, 512)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "    '''def forward_once(self, x):\n",
        "        # Forward pass\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output'''\n",
        "\n",
        "    def forward_once(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        #logits = self.classifier(pooled_output)\n",
        "\n",
        "        return pooled_output\n",
        "\n",
        "    def forward(self, input_ids1, input_ids2, input_ids3, credit_sc):\n",
        "        # forward pass of input 1\n",
        "        output1 = self.forward_once(input_ids1, token_type_ids=None, attention_mask=None, labels=None)\n",
        "        # forward pass of input 2\n",
        "        output2 = self.forward_once(input_ids2, token_type_ids=None, attention_mask=None, labels=None)\n",
        "\n",
        "        output3 = self.forward_once(input_ids3, token_type_ids=None, attention_mask=None, labels=None)\n",
        "\n",
        "        out = torch.cat((output1, output2, output3), 1)\n",
        "        #print(out.shape)\n",
        "\n",
        "        # Multiply the credit score with the output after concatnation\n",
        "\n",
        "        out = torch.add(credit_sc, out)\n",
        "\n",
        "        #out = self.fc1(out)\n",
        "        logits = self.classifier(out)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUThsowyQdN7"
      },
      "source": [
        "## INIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGoiXd70tb5z"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "model = BertForSequenceClassification().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model,x,y,z,m)"
      ],
      "metadata": {
        "id": "F1jmeZiwHJn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyCA5fvyVkb0"
      },
      "outputs": [],
      "source": [
        "gc.collect() # These commands help you when you face CUDA OOM error\n",
        "torch.cuda.empty_cache()\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnTLL-5gMBrY"
      },
      "outputs": [],
      "source": [
        "train_acc = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "val_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, scheduler):\n",
        "    since = Time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 100\n",
        "    best_acc = 0\n",
        "\n",
        "    scheduler.step()\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    fakeness_corrects = 0\n",
        "     # Progress Bar \n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5) \n",
        "    # Iterate over data.\n",
        "    for data in train_loader:\n",
        "        inputs = data[0:4]\n",
        "        fakeness = data[-1]\n",
        "\n",
        "        inputs1 = inputs[0] # News statement input\n",
        "        inputs2 = inputs[1] # Justification input\n",
        "        inputs3 = inputs[2] # Meta data input\n",
        "        inputs4 = inputs[3] # Credit scores input\n",
        "\n",
        "        inputs1 = inputs1.to(device)\n",
        "        inputs2 = inputs2.to(device)\n",
        "        inputs3 = inputs3.to(device)\n",
        "        inputs4 = inputs4.to(device)\n",
        "\n",
        "        fakeness = fakeness.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs1, inputs2, inputs3, inputs4)\n",
        "            outputs = F.softmax(outputs,dim=1)\n",
        "            loss = criterion(outputs, torch.max(fakeness.float(), 1)[1])\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs1.size(0)\n",
        "\n",
        "\n",
        "        fakeness_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(fakeness, 1)[1])\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * fakeness_corrects / (config['batch_size']*(i + 1))),\n",
        "            loss=\"{:.04f}\".format(float(running_loss / (i + 1))),\n",
        "            num_correct=fakeness_corrects.item(),\n",
        "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "        \n",
        "        # loss.backward()\n",
        "        scaler.scale(loss).backward()\n",
        "        # optimizer.step()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "\n",
        "        batch_bar.update()\n",
        "\n",
        "    batch_bar.close()\n",
        "    epoch_loss = running_loss / len(X_train)\n",
        "\n",
        "\n",
        "    fakeness_acc = fakeness_corrects.double() / len(X_train)\n",
        "\n",
        "    print('Train total loss: {:.4f} '.format(epoch_loss))\n",
        "    print('Train fakeness_acc: {:.4f}'.format(fakeness_acc))\n",
        "\n",
        "    # Saving training acc and loss for each epoch\n",
        "    fakeness_acc1 = fakeness_acc.data\n",
        "    fakeness_acc1 = fakeness_acc1.cpu()\n",
        "    fakeness_acc1 = fakeness_acc1.numpy()\n",
        "    train_acc.append(fakeness_acc1)\n",
        "\n",
        "    #epoch_loss1 = epoch_loss.data\n",
        "    #epoch_loss1 = epoch_loss1.cpu()\n",
        "    #epoch_loss1 = epoch_loss1.numpy()\n",
        "    train_loss.append(epoch_loss)\n",
        "\n",
        "    return train_acc, train_loss"
      ],
      "metadata": {
        "id": "oiuoAWxgPo_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, criterion, optimizer, scheduler):\n",
        "    since = Time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 100\n",
        "    best_acc = 0\n",
        "    # Each epoch has a training and validation phase\n",
        "\n",
        "    model.eval()   # Set model to evaluate mode\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    fakeness_corrects = 0\n",
        "\n",
        "    # Iterate over data.\n",
        "    for data in val_loader:\n",
        "        inputs = data[0:4]\n",
        "        fakeness = data[-1]\n",
        "        inputs1 = inputs[0] # News statement input\n",
        "        inputs2 = inputs[1] # Justification input\n",
        "        inputs3 = inputs[2] # Meta data input\n",
        "        inputs4 = inputs[3] # Credit scores input\n",
        "\n",
        "        inputs1 = inputs1.to(device)\n",
        "        inputs2 = inputs2.to(device)\n",
        "        inputs3 = inputs3.to(device)\n",
        "        inputs4 = inputs4.to(device)\n",
        "\n",
        "        fakeness = fakeness.to(device)\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        outputs = model(inputs1, inputs2, inputs3, inputs4)\n",
        "\n",
        "        outputs = F.softmax(outputs,dim=1)\n",
        "\n",
        "        loss = criterion(outputs, torch.max(fakeness.float(), 1)[1])\n",
        "        # backward + optimize only if in training phase\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs1.size(0)\n",
        "\n",
        "\n",
        "        fakeness_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(fakeness, 1)[1])\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * fakeness_corrects / (config['batch_size']*(i + 1))),\n",
        "            loss=\"{:.04f}\".format(float(running_loss / (i + 1))),\n",
        "            num_correct=fakeness_corrects.item(),\n",
        "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "        batch_bar.update()\n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(X_val)\n",
        "    fakeness_acc = fakeness_corrects.double() / len(X_val)\n",
        "\n",
        "    print('Validation total loss: {:.4f} '.format(epoch_loss ))\n",
        "    print('Validation fakeness_acc: {:.4f}'.format(fakeness_acc))\n",
        "    best_acc = fakeness_acc\n",
        "\n",
        "    # Saving val acc and loss for each epoch\n",
        "    fakeness_acc1 = fakeness_acc.data\n",
        "    fakeness_acc1 = fakeness_acc1.cpu()\n",
        "    fakeness_acc1 = fakeness_acc1.numpy()\n",
        "    val_acc.append(fakeness_acc1)\n",
        "\n",
        "    #epoch_loss1 = epoch_loss.data\n",
        "    #epoch_loss1 = epoch_loss1.cpu()\n",
        "    #epoch_loss1 = epoch_loss1.numpy()\n",
        "    val_loss.append(epoch_loss)\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(float(best_acc)))\n",
        "\n",
        "    return val_acc, val_loss"
      ],
      "metadata": {
        "id": "fbpr1VaQT8O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiDduMaDIARE"
      },
      "outputs": [],
      "source": [
        "wandb.login(key=\"3c0882202a0a1f93d55e16a0e94007adf1a84943\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s52yBOvICPZ"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(\n",
        "    name = \"project_ablations_2\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    #id = '2lq40515', #Insert specific run id here if you want to resume a previous run\n",
        "    #resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project=\"DL_project\", ### Project should be created in your wandb account \n",
        "    config=config, ### Wandb Config for your run\n",
        "    entity=\"the-spinning-top\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fLLj5KIMMOe"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nqLiAmkMMBc"
      },
      "outputs": [],
      "source": [
        "lrlast = .0001\n",
        "lrmain = .00001\n",
        "optim1 = torch.optim.Adam(\n",
        "    [\n",
        "        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n",
        "        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n",
        "\n",
        "   ])\n",
        "\n",
        "#optim1 = optim.Adam(model.parameters(), lr=0.001)#,momentum=.9)\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "'''import focal_loss\n",
        "loss_args = {\"alpha\": 0.5, \"gamma\": 2.0}\n",
        "criterion = focal_loss.FocalLoss(*loss_args)'''\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 3 epochs\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpYExu4vT4_g"
      },
      "source": [
        "### Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tExvyl1BIdMC"
      },
      "outputs": [],
      "source": [
        "#sanity check\n",
        "# train_acc, train_loss = train(model, criterion, optimizer_ft, exp_lr_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check\n",
        "# val_acc, val_loss = validation(model, criterion, optimizer_ft, exp_lr_scheduler)"
      ],
      "metadata": {
        "id": "Dc80qm1jL3sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# float(accuracy[-1])"
      ],
      "metadata": {
        "id": "Xu4joDb8wZAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# float(train_loss[-1])"
      ],
      "metadata": {
        "id": "5ZnRCTSgJHFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# float(val_loss[-1])"
      ],
      "metadata": {
        "id": "rIisuxBvJORn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# float(train_acc[-1])"
      ],
      "metadata": {
        "id": "36ItAQsxJVBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over number of epochs to train and evaluate your model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "best_acc = 0.0 ### Monitor best accuracy in your run\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
        "    #t0 = time.time()\n",
        "\n",
        "    train_acc, train_loss = train(model, criterion, optimizer_ft, exp_lr_scheduler)\n",
        "    accuracy, val_loss = validation(model, criterion, optimizer_ft, exp_lr_scheduler)\n",
        "\n",
        "\n",
        "    wandb.log({\"train loss\": float(train_loss[-1]), \"validation accuracy\": float(accuracy[-1]), \"val_loss\": float(val_loss[-1]), \"train acc\":float(train_acc[-1])})\n",
        "    #scheduler.step(accuracy) #ReduceLRonPlateau\n",
        "    exp_lr_scheduler.step() #StepLR\n",
        "\n",
        "    ### Log metrics at each epoch in your run - Optionally, you can log at each batch inside train/eval functions (explore wandb documentation/wandb recitation)\n",
        "\n",
        "\n",
        "    ### Save checkpoint at each epoch\n",
        "    ### Save checkpoint with information you want\n",
        "    if float(accuracy[-1])<best_acc:\n",
        "        best_acc = float(accuracy[-1])\n",
        "        print('Saving model...')\n",
        "        torch.save({'epoch': epoch,\n",
        "                  'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer_ft.state_dict(),\n",
        "                  'loss': train_loss,\n",
        "                  'acc': accuracy}, \n",
        "            './model_checkpoint.pth')\n",
        "          \n",
        "          ### Save checkpoint in wandb\n",
        "        wandb.save('checkpoint.pth')\n",
        "\n",
        "    # Is your training time very high? Look into mixed precision training if your GPU (Tesla T4, V100, etc) can make use of it \n",
        "    # Refer - https://pytorch.org/docs/stable/notes/amp_examples.html\n",
        "    #print('Duration:',time.time() - t0)\n",
        "### Finish your wandb run\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "MWUEh273d1Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbO4RiEhwl4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb4a7f07a05e69ccd70b8610395539af4ea9eff6155ae8b28a9ee451516f169c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}